# import torch
# import torch.nn as nn
# from torchvision import models, transforms
# from PIL import Image
# import os
# import argparse
# import sys

# class LandmarkPredictor:
#     def __init__(self, model_path='best_landmark_model_finetuned.pt'):
#         """
#         åˆå§‹åŒ–åœ°æ ‡è¯†åˆ«é¢„æµ‹å™¨
        
#         Args:
#             model_path: è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶è·¯å¾„
#         """
#         self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
#         self.model_path = model_path
        
#         # æ•°æ®é¢„å¤„ç†ç®¡é“ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
#         self.transform = transforms.Compose([
#             transforms.Resize(256),
#             transforms.CenterCrop(224),
#             transforms.ToTensor(),
#             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
#         ])
        
#         # æ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„ç±»åˆ«åç§°ï¼ˆæŒ‰å­—æ¯é¡ºåºï¼Œä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
#         self.class_names = [
#             'Gilis', 'baolihui', 'ccb', 'chaimengongguan', 'chengduyan', 
#             'communitycenter', 'dianyingyuan', 'flouxetine', 'kaibinsiji', 'luji', 'morgan', 
#             'ouzhoufengqingjie', 'sijiguo', 'wanlijiudian', 'weishengzhongxin', 'yangya', 
#             'yingdangbaoyu', 'yinyuefangzi'
#         ]
        
#         # åœ°æ ‡ä¸­æ–‡åç§°æ˜ å°„
#         self.chinese_names = {
#             'Gilis': 'å…¶å¿ƒè¥¿é¤å…',
#             'baolihui': 'å®åˆ©æ±‡',
#             'ccb': 'å»ºè®¾é“¶è¡Œ',
#             'chaimengongguan': 'æŸ´é—¨å…¬é¦† (æ¡æ¢“æ—åº—)',
#             'chengduyan': 'æˆéƒ½å®´ (æ¡æ¢“æ—åº—)',
#             'communitycenter': 'ç¤¾åŒºæ´»åŠ¨ä¸­å¿ƒ',
#             'dianyingyuan': 'ç´«è†ç”µå½±é™¢',
#             'flouxetine': 'æ°Ÿè¥¿æ±€Whisky&Cocktail Bar (æ¡æ¢“æ—åº—)',
#             'kaibinsiji': 'æˆéƒ½å‡¯å®¾æ–¯åŸºé¥­åº—',
#             'luji': 'å¢è®°æ­£è¡—é¥­åº—Â·å·æ¹˜èœ',
#             'morgan': 'æ‘©æ ¹æ‰’æˆ¿',
#             'ouzhoufengqingjie': 'æ¡æ¢“æ—æ¬§æ´²é£æƒ…è¡—',
#             'sijiguo': 'å››å­£é”…ç«é”… (æ¡æ¢“æ—åº—)',
#             'wanlijiudian': 'æˆéƒ½é¦–åº§ä¸‡ä¸½é…’åº—',
#             'weishengzhongxin': 'å«ç”Ÿä¸­å¿ƒ',
#             'yangya': 'æ¼¾äºšÂ·é›é›…åˆé²œ (æ¡æ¢“æ—åº—)',
#             'yingdangbaoyu': 'é“¶æ»©é²é±¼ç«é”… (å¸Œæœ›è·¯åº—)',
#             'yinyuefangzi': 'éŸ³ä¹æˆ¿å­ (ç‰æ—åº—)'
#         }
        
#         # åœ°æ ‡åˆ†ç±»
#         self.landmark_categories = {
#             'é¤å…': [
#                 'æˆéƒ½å®´ (æ¡æ¢“æ—åº—)', 'æŸ´é—¨å…¬é¦† (æ¡æ¢“æ—åº—)', 'æ¼¾äºšÂ·é›é›…åˆé²œ (æ¡æ¢“æ—åº—)',
#                 'é“¶æ»©é²é±¼ç«é”… (å¸Œæœ›è·¯åº—)', 'å…¶å¿ƒè¥¿é¤å…', 'æ‘©æ ¹æ‰’æˆ¿',
#                 'å››å­£é”…ç«é”… (æ¡æ¢“æ—åº—)', 'å¢è®°æ­£è¡—é¥­åº—Â·å·æ¹˜èœ'
#             ],
#             'é…’å§': [
#                 'æ°Ÿè¥¿æ±€Whisky&Cocktail Bar (æ¡æ¢“æ—åº—)', 'éŸ³ä¹æˆ¿å­ (ç‰æ—åº—)'
#             ],
#             'å…¬å…±æœåŠ¡': [
#                 'ç¤¾åŒºæ´»åŠ¨ä¸­å¿ƒ', 'å«ç”Ÿä¸­å¿ƒ'
#             ],
#             'å¨±ä¹ä¸å…¶ä»–': [
#                 'æ¡æ¢“æ—æ¬§æ´²é£æƒ…è¡—', 'ç´«è†ç”µå½±é™¢', 'æˆéƒ½å‡¯å®¾æ–¯åŸºé¥­åº—',
#                 'æˆéƒ½é¦–åº§ä¸‡ä¸½é…’åº—', 'å»ºè®¾é“¶è¡Œ', 'å®åˆ©æ±‡'
#             ]
#         }
        
#         self.num_classes = len(self.class_names)
#         self.model = None
        
#         # åŠ è½½æ¨¡å‹
#         self._load_model()
    
#     def get_chinese_name(self, english_name):
#         """è·å–åœ°æ ‡çš„ä¸­æ–‡åç§°"""
#         return self.chinese_names.get(english_name, english_name)
    
#     def get_landmark_category(self, chinese_name):
#         """è·å–åœ°æ ‡çš„åˆ†ç±»"""
#         for category, landmarks in self.landmark_categories.items():
#             if chinese_name in landmarks:
#                 return category
#         return "æœªåˆ†ç±»"
    
#     def _load_model(self):
#         """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
#         try:
#             print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
#             print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
            
#             # åˆ›å»ºæ¨¡å‹æ¶æ„
#             self.model = models.mobilenet_v3_large(weights=None)
#             num_ftrs = self.model.classifier[3].in_features
#             self.model.classifier[3] = nn.Linear(num_ftrs, self.num_classes)
            
#             # åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
#             checkpoint = torch.load(self.model_path, map_location=self.device, weights_only=True)
#             self.model.load_state_dict(checkpoint)
            
#             # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
#             self.model = self.model.to(self.device)
#             self.model.eval()
            
#             print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
#             print(f"æ”¯æŒè¯†åˆ«çš„åœ°æ ‡ç±»åˆ«: {len(self.class_names)} ä¸ª")
            
#             # æŒ‰åˆ†ç±»æ˜¾ç¤ºæ”¯æŒçš„åœ°æ ‡
#             print("\nğŸ“ æ”¯æŒè¯†åˆ«çš„åœ°æ ‡:")
#             for category, landmarks in self.landmark_categories.items():
#                 print(f"  {category}: {', '.join(landmarks)}")
            
#         except Exception as e:
#             print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
#             sys.exit(1)
    
#     def predict_image(self, image_path, show_top_k=3):
#         """
#         é¢„æµ‹å•å¼ å›¾ç‰‡çš„åœ°æ ‡ç±»åˆ«
        
#         Args:
#             image_path: å›¾ç‰‡æ–‡ä»¶è·¯å¾„
#             show_top_k: æ˜¾ç¤ºå‰Kä¸ªæœ€å¯èƒ½çš„é¢„æµ‹ç»“æœ
            
#         Returns:
#             dict: åŒ…å«é¢„æµ‹ç»“æœçš„å­—å…¸
#         """
#         try:
#             # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
#             if not os.path.exists(image_path):
#                 raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            
#             # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
#             image = Image.open(image_path).convert('RGB')
#             input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
#             # è¿›è¡Œé¢„æµ‹
#             with torch.no_grad():
#                 outputs = self.model(input_tensor)
#                 probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
                
#                 # è·å–æœ€é«˜æ¦‚ç‡çš„é¢„æµ‹
#                 _, predicted = torch.max(outputs, 1)
#                 predicted_english = self.class_names[predicted.item()]
#                 predicted_chinese = self.get_chinese_name(predicted_english)
#                 confidence = probabilities[predicted.item()].item() * 100
#                 category = self.get_landmark_category(predicted_chinese)
                
#                 # è·å–å‰Kä¸ªæœ€å¯èƒ½çš„é¢„æµ‹
#                 top_k_prob, top_k_idx = torch.topk(probabilities, min(show_top_k, len(self.class_names)))
#                 top_k_results = []
#                 for i in range(len(top_k_prob)):
#                     english_name = self.class_names[top_k_idx[i]]
#                     chinese_name = self.get_chinese_name(english_name)
#                     top_k_results.append({
#                         'landmark_english': english_name,
#                         'landmark_chinese': chinese_name,
#                         'landmark': chinese_name,  # ä¿æŒå‘åå…¼å®¹
#                         'confidence': top_k_prob[i].item() * 100
#                     })
                
#                 return {
#                     'image_path': image_path,
#                     'predicted_landmark_english': predicted_english,
#                     'predicted_landmark_chinese': predicted_chinese,
#                     'predicted_landmark': predicted_chinese,  # ä¿æŒå‘åå…¼å®¹
#                     'landmark_category': category,
#                     'confidence': confidence,
#                     'top_k_predictions': top_k_results,
#                     'success': True
#                 }
                
#         except Exception as e:
#             return {
#                 'image_path': image_path,
#                 'error': str(e),
#                 'success': False
#             }
    
import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image
import os
import argparse
import sys
import io  # å¯¼å…¥ io æ¨¡å—

class LandmarkPredictor:
    def __init__(self, model_path='best_landmark_model_finetuned.pt'):
        """
        åˆå§‹åŒ–åœ°æ ‡è¯†åˆ«é¢„æµ‹å™¨
        """
        # ===================================================================
        #  â†“â†“â†“â†“â†“ å…³é”®ä¿®å¤ 1: ä½¿ç”¨ç»å¯¹è·¯å¾„åŠ è½½æ¨¡å‹ â†“â†“â†“â†“â†“
        # ===================================================================
        # è·å–å½“å‰è„šæœ¬æ–‡ä»¶æ‰€åœ¨çš„ç»å¯¹ç›®å½•
        base_dir = os.path.dirname(os.path.abspath(__file__))
        # å°†æ¨¡å‹è·¯å¾„æ‹¼æ¥æˆç»å¯¹è·¯å¾„
        self.model_path = os.path.join(base_dir, model_path)
        # ===================================================================
        #  â†‘â†‘â†‘â†‘â†‘ è·¯å¾„ä¿®å¤ç»“æŸ â†‘â†‘â†‘â†‘â†‘
        # ===================================================================
        
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        
        # æ•°æ®é¢„å¤„ç†ç®¡é“ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # --- ä½ åŸæœ‰çš„æ‰€æœ‰æ•°æ®éƒ½å®Œæ•´ä¿ç•™ ---
        self.class_names = [
            'Gilis', 'baolihui', 'ccb', 'chaimengongguan', 'chengduyan', 
            'communitycenter', 'dianyingyuan', 'flouxetine', 'kaibinsiji', 'luji', 'morgan', 
            'ouzhoufengqingjie', 'sijiguo', 'wanlijiudian', 'weishengzhongxin', 'yangya', 
            'yingdangbaoyu', 'yinyuefangzi'
        ]
        self.chinese_names = {
            'Gilis': 'å…¶å¿ƒè¥¿é¤å…', 'baolihui': 'å®åˆ©æ±‡', 'ccb': 'å»ºè®¾é“¶è¡Œ',
            'chaimengongguan': 'æŸ´é—¨å…¬é¦† (æ¡æ¢“æ—åº—)', 'chengduyan': 'æˆéƒ½å®´ (æ¡æ¢“æ—åº—)',
            'communitycenter': 'ç¤¾åŒºæ´»åŠ¨ä¸­å¿ƒ', 'dianyingyuan': 'ç´«è†ç”µå½±é™¢',
            'flouxetine': 'æ°Ÿè¥¿æ±€Whisky&Cocktail Bar (æ¡æ¢“æ—åº—)', 'kaibinsiji': 'æˆéƒ½å‡¯å®¾æ–¯åŸºé¥­åº—',
            'luji': 'å¢è®°æ­£è¡—é¥­åº—Â·å·æ¹˜èœ', 'morgan': 'æ‘©æ ¹æ‰’æˆ¿',
            'ouzhoufengqingjie': 'æ¡æ¢“æ—æ¬§æ´²é£æƒ…è¡—', 'sijiguo': 'å››å­£é”…ç«é”… (æ¡æ¢“æ—åº—)',
            'wanlijiudian': 'æˆéƒ½é¦–åº§ä¸‡ä¸½é…’åº—', 'weishengzhongxin': 'å«ç”Ÿä¸­å¿ƒ',
            'yangya': 'æ¼¾äºšÂ·é›é›…åˆé²œ (æ¡æ¢“æ—åº—)', 'yingdangbaoyu': 'é“¶æ»©é²é±¼ç«é”… (å¸Œæœ›è·¯åº—)',
            'yinyuefangzi': 'éŸ³ä¹æˆ¿å­ (ç‰æ—åº—)'
        }
        self.landmark_categories = {
            'é¤å…': ['æˆéƒ½å®´ (æ¡æ¢“æ—åº—)', 'æŸ´é—¨å…¬é¦† (æ¡æ¢“æ—åº—)', 'æ¼¾äºšÂ·é›é›…åˆé²œ (æ¡æ¢“æ—åº—)', 'é“¶æ»©é²é±¼ç«é”… (å¸Œæœ›è·¯åº—)', 'å…¶å¿ƒè¥¿é¤å…', 'æ‘©æ ¹æ‰’æˆ¿', 'å››å­£é”…ç«é”… (æ¡æ¢“æ—åº—)', 'å¢è®°æ­£è¡—é¥­åº—Â·å·æ¹˜èœ'],
            'é…’å§': ['æ°Ÿè¥¿æ±€Whisky&Cocktail Bar (æ¡æ¢“æ—åº—)', 'éŸ³ä¹æˆ¿å­ (ç‰æ—åº—)'],
            'å…¬å…±æœåŠ¡': ['ç¤¾åŒºæ´»åŠ¨ä¸­å¿ƒ', 'å«ç”Ÿä¸­å¿ƒ'],
            'å¨±ä¹ä¸å…¶ä»–': ['æ¡æ¢“æ—æ¬§æ´²é£æƒ…è¡—', 'ç´«è†ç”µå½±é™¢', 'æˆéƒ½å‡¯å®¾æ–¯åŸºé¥­åº—', 'æˆéƒ½é¦–åº§ä¸‡ä¸½é…’åº—', 'å»ºè®¾é“¶è¡Œ', 'å®åˆ©æ±‡']
        }
        
        self.num_classes = len(self.class_names)
        self.model = None
        self._load_model()
    
    # --- ä½ åŸæœ‰çš„æ‰€æœ‰æ–¹æ³•éƒ½å®Œæ•´ä¿ç•™ ---
    def get_chinese_name(self, english_name):
        return self.chinese_names.get(english_name, english_name)
    
    def get_landmark_category(self, chinese_name):
        for category, landmarks in self.landmark_categories.items():
            if chinese_name in landmarks:
                return category
        return "æœªåˆ†ç±»"
    
    def _load_model(self):
        try:
            print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
            print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(self.model_path):
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.model_path}")

            # ä¿æŒä½ åŸæœ‰çš„æ¨¡å‹æ¶æ„
            self.model = models.mobilenet_v3_large(weights=None)
            # æ³¨æ„ï¼šè¿™é‡Œçš„ classifier[3] æ˜¯æ ¹æ®ä½ åŸå§‹ä»£ç æ¥çš„ï¼Œéå¸¸é‡è¦
            num_ftrs = self.model.classifier[3].in_features
            self.model.classifier[3] = nn.Linear(num_ftrs, self.num_classes)
            
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.model.load_state_dict(checkpoint)
            
            self.model = self.model.to(self.device)
            self.model.eval()
            print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # åœ¨ Django ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬ä¸åº”è¯¥é€€å‡ºç¨‹åºï¼Œè€Œæ˜¯è®© model ä¿æŒä¸º None
            self.model = None
    
    # ===================================================================
    #  â†“â†“â†“â†“â†“ å…³é”®ä¿®å¤ 2: æ–°å¢ä¸€ä¸ªæ–¹æ³•æ¥å¤„ç† Django ä¼ æ¥çš„å›¾ç‰‡æ•°æ® â†“â†“â†“â†“â†“
    # ===================================================================
    def predict(self, image_bytes):
        """
        ä¸“é—¨ä¸º Django è®¾è®¡çš„é¢„æµ‹æ–¹æ³•ï¼Œæ¥æ”¶å†…å­˜ä¸­çš„å›¾ç‰‡å­—èŠ‚æµ
        """
        if not self.model:
            raise Exception("æ¨¡å‹æœªèƒ½æˆåŠŸåŠ è½½ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹ã€‚")

        # ä»å­—èŠ‚æµä¸­åŠ è½½å›¾ç‰‡
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = torch.nn.functional.softmax(outputs[0], dim=0)
            
            _, predicted = torch.max(outputs, 1)
            predicted_english = self.class_names[predicted.item()]
            predicted_chinese = self.get_chinese_name(predicted_english)
            confidence = probabilities[predicted.item()].item() * 100
            
        # è¿”å›è°ƒåº¦ä¸­å¿ƒéœ€è¦çš„æ•°æ®æ ¼å¼ï¼š(åœ°æ ‡ä¸­æ–‡å, ç½®ä¿¡åº¦)
        return predicted_chinese, confidence
    # ===================================================================
    #  â†‘â†‘â†‘â†‘â†‘ æ–°å¢æ–¹æ³•ç»“æŸ â†‘â†‘â†‘â†‘â†‘
    # ===================================================================

    # --- ä½ åŸæœ‰çš„å…¶ä»–æ–¹æ³• (predict_image, predict_batch ç­‰) éƒ½å®Œæ•´ä¿ç•™åœ¨ä¸‹æ–¹ ---
    # --- è¿™æ ·ä½ çš„è„šæœ¬ä»ç„¶å¯ä»¥ç‹¬ç«‹è¿è¡Œè¿›è¡Œæµ‹è¯• ---
    def predict_image(self, image_path, show_top_k=3):
        try:
            if not os.path.exists(image_path):
                raise FileNotFoundError(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
            # ä»æ–‡ä»¶è·¯å¾„åŠ è½½å›¾ç‰‡
            with open(image_path, 'rb') as f:
                image_bytes = f.read()
            # å¤ç”¨æ–°çš„ predict æ–¹æ³•
            predicted_chinese, confidence = self.predict(image_bytes)

            # ä¸ºäº†ä¿æŒåŸæœ‰å‡½æ•°çš„è¾“å‡ºæ ¼å¼ï¼Œæˆ‘ä»¬åœ¨è¿™é‡Œé‡æ–°ç»„ç»‡ä¸€ä¸‹
            predicted_english = [k for k, v in self.chinese_names.items() if v == predicted_chinese][0]
            category = self.get_landmark_category(predicted_chinese)

            # æ­¤å¤„ç®€åŒ–äº† top_k çš„é€»è¾‘ï¼Œåªè¿”å›æœ€ä¸»è¦çš„é¢„æµ‹ç»“æœ
            top_k_results = [{
                'landmark_english': predicted_english,
                'landmark_chinese': predicted_chinese,
                'landmark': predicted_chinese, # ä¿æŒå‘åå…¼å®¹
                'confidence': confidence
            }]

            return {
                'image_path': image_path,
                'predicted_landmark_english': predicted_english,
                'predicted_landmark_chinese': predicted_chinese,
                'predicted_landmark': predicted_chinese, # ä¿æŒå‘åå…¼å®¹
                'landmark_category': category,
                'confidence': confidence,
                'top_k_predictions': top_k_results,
                'success': True
            }
        except Exception as e:
            return {'image_path': image_path, 'error': str(e), 'success': False}
    
    # ... (ä½ å…¶ä»–çš„ predict_batch, print_prediction_result, main å‡½æ•°ç­‰éƒ½å¯ä»¥åœ¨è¿™é‡Œç»§ç»­ä¿ç•™) ...

    def predict_batch(self, image_paths, show_top_k=3):
        """
        æ‰¹é‡é¢„æµ‹å¤šå¼ å›¾ç‰‡
        
        Args:
            image_paths: å›¾ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            show_top_k: æ˜¾ç¤ºå‰Kä¸ªæœ€å¯èƒ½çš„é¢„æµ‹ç»“æœ
            
        Returns:
            list: åŒ…å«æ‰€æœ‰é¢„æµ‹ç»“æœçš„åˆ—è¡¨
        """
        results = []
        total_images = len(image_paths)
        
        print(f"å¼€å§‹æ‰¹é‡é¢„æµ‹ {total_images} å¼ å›¾ç‰‡...")
        print("-" * 60)
        
        for i, image_path in enumerate(image_paths, 1):
            print(f"å¤„ç†ç¬¬ {i}/{total_images} å¼ å›¾ç‰‡: {os.path.basename(image_path)}")
            result = self.predict_image(image_path, show_top_k)
            results.append(result)
            
            if result['success']:
                print(f"âœ… é¢„æµ‹ç»“æœ: {result['predicted_landmark_chinese']} (ç½®ä¿¡åº¦: {result['confidence']:.2f}%)")
                print(f"   åˆ†ç±»: {result['landmark_category']}")
            else:
                print(f"âŒ é¢„æµ‹å¤±è´¥: {result['error']}")
            print()
        
        return results
    
    def print_prediction_result(self, result):
        """æ ¼å¼åŒ–æ‰“å°é¢„æµ‹ç»“æœ"""
        if not result['success']:
            print(f"âŒ é¢„æµ‹å¤±è´¥: {result['error']}")
            return
        
        print(f"ğŸ–¼ï¸  å›¾ç‰‡: {os.path.basename(result['image_path'])}")
        print(f"ğŸ¯ é¢„æµ‹åœ°æ ‡: {result['predicted_landmark_chinese']}")
        print(f"ğŸ·ï¸  åœ°æ ‡åˆ†ç±»: {result['landmark_category']}")
        print(f"ğŸ“Š ç½®ä¿¡åº¦: {result['confidence']:.2f}%")
        
        if result['top_k_predictions']:
            print(f"\nğŸ“‹ è¯¦ç»†é¢„æµ‹ç»“æœ:")
            for i, pred in enumerate(result['top_k_predictions'], 1):
                category = self.get_landmark_category(pred['landmark_chinese'])
                print(f"   {i}. {pred['landmark_chinese']} ({category}): {pred['confidence']:.2f}%")

def main():
    # å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description='åœ°æ ‡è¯†åˆ«ç¨‹åº - æ¡æ¢“æ—ç¤¾åŒºåœ°æ ‡è¯†åˆ«ç³»ç»Ÿ')
    parser.add_argument('--image', '-i', type=str, help='å•å¼ å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--batch', '-b', type=str, nargs='+', help='å¤šå¼ å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--folder', '-f', type=str, help='å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--model', '-m', type=str, default='best_landmark_model_finetuned.pt', 
                       help='æ¨¡å‹æ–‡ä»¶è·¯å¾„ (é»˜è®¤: best_landmark_model_finetuned.pt)')
    parser.add_argument('--top-k', '-k', type=int, default=3, 
                       help='æ˜¾ç¤ºå‰Kä¸ªé¢„æµ‹ç»“æœ (é»˜è®¤: 3)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥å‚æ•°
    if not any([args.image, args.batch, args.folder]):
        print("ğŸ™ï¸ æ¡æ¢“æ—ç¤¾åŒºåœ°æ ‡è¯†åˆ«ç³»ç»Ÿ")
        print("è¯·æŒ‡å®šè¦é¢„æµ‹çš„å›¾ç‰‡:")
        print("  å•å¼ å›¾ç‰‡: python landmark_predictor.py --image path/to/image.jpg")
        print("  å¤šå¼ å›¾ç‰‡: python landmark_predictor.py --batch image1.jpg image2.jpg")
        print("  æ•´ä¸ªæ–‡ä»¶å¤¹: python landmark_predictor.py --folder path/to/folder")
        return
    
    # åˆå§‹åŒ–é¢„æµ‹å™¨
    predictor = LandmarkPredictor(args.model)
    print("\n" + "="*60)
    
    # æ‰§è¡Œé¢„æµ‹
    if args.image:
        # å•å¼ å›¾ç‰‡é¢„æµ‹
        print("ğŸ” å•å¼ å›¾ç‰‡é¢„æµ‹æ¨¡å¼")
        print("="*60)
        result = predictor.predict_image(args.image, args.top_k)
        predictor.print_prediction_result(result)
        
    elif args.batch:
        # æ‰¹é‡å›¾ç‰‡é¢„æµ‹
        print("ğŸ” æ‰¹é‡å›¾ç‰‡é¢„æµ‹æ¨¡å¼")
        print("="*60)
        results = predictor.predict_batch(args.batch, args.top_k)
        
        # ç»Ÿè®¡æˆåŠŸç‡å’Œåˆ†ç±»ç»Ÿè®¡
        successful = sum(1 for r in results if r['success'])
        category_stats = {}
        for result in results:
            if result['success']:
                category = result['landmark_category']
                category_stats[category] = category_stats.get(category, 0) + 1
        
        print(f"\nğŸ“ˆ é¢„æµ‹ç»Ÿè®¡:")
        print(f"   æ€»è®¡: {len(results)} å¼ å›¾ç‰‡")
        print(f"   æˆåŠŸ: {successful} å¼ ")
        print(f"   å¤±è´¥: {len(results) - successful} å¼ ")
        print(f"   æˆåŠŸç‡: {successful/len(results)*100:.1f}%")
        
        if category_stats:
            print(f"\nğŸ“Š åœ°æ ‡åˆ†ç±»ç»Ÿè®¡:")
            for category, count in category_stats.items():
                print(f"   {category}: {count} å¼ ")
        
    elif args.folder:
        # æ–‡ä»¶å¤¹é¢„æµ‹
        print("ğŸ” æ–‡ä»¶å¤¹é¢„æµ‹æ¨¡å¼")
        print("="*60)
        
        if not os.path.exists(args.folder):
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {args.folder}")
            return
        
        # è·å–æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp')
        image_paths = []
        
        for filename in os.listdir(args.folder):
            if filename.lower().endswith(image_extensions):
                image_paths.append(os.path.join(args.folder, filename))
        
        if not image_paths:
            print(f"âŒ åœ¨æ–‡ä»¶å¤¹ {args.folder} ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return
        
        print(f"æ‰¾åˆ° {len(image_paths)} å¼ å›¾ç‰‡")
        results = predictor.predict_batch(image_paths, args.top_k)
        
        # ç»Ÿè®¡æˆåŠŸç‡å’Œåˆ†ç±»ç»Ÿè®¡
        successful = sum(1 for r in results if r['success'])
        category_stats = {}
        for result in results:
            if result['success']:
                category = result['landmark_category']
                category_stats[category] = category_stats.get(category, 0) + 1
        
        print(f"ğŸ“ˆ é¢„æµ‹ç»Ÿè®¡:")
        print(f"   æ€»è®¡: {len(results)} å¼ å›¾ç‰‡")
        print(f"   æˆåŠŸ: {successful} å¼ ")
        print(f"   å¤±è´¥: {len(results) - successful} å¼ ")
        print(f"   æˆåŠŸç‡: {successful/len(results)*100:.1f}%")
        
        if category_stats:
            print(f"\nğŸ“Š åœ°æ ‡åˆ†ç±»ç»Ÿè®¡:")
            for category, count in category_stats.items():
                print(f"   {category}: {count} å¼ ")

if __name__ == "__main__":
    main()
